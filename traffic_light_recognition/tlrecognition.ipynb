{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd477bf3-accb-480e-9324-b4a40adc6b21",
      "metadata": {
        "id": "cd477bf3-accb-480e-9324-b4a40adc6b21",
        "outputId": "4f68fa98-dd0f-4217-88c8-cd6c8a479c82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.13/site-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.13/site-packages (from opencv-python) (2.1.3)\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'cv2'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install opencv-python --break-system-packages\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "!pip install opencv-python --break-system-packages\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def read_ground_truth(file_path):\n",
        "    import re  # Regular expressions for parsing\n",
        "\n",
        "    with open(file_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    data = []\n",
        "    for line in lines:\n",
        "        if line.startswith(\"#\"):\n",
        "            continue\n",
        "\n",
        "        # Adjust regex to allow negative coordinates\n",
        "        match = re.match(\n",
        "            r\"(\\S+)\\s*/\\s*(\\d+)\\s+(-?\\d+)\\s+(-?\\d+)\\s+(-?\\d+)\\s+(-?\\d+)\\s+(\\d+)\\s+'([^']+)'\\s+'([^']+)'\",\n",
        "            line.strip()\n",
        "        )\n",
        "\n",
        "        if not match:\n",
        "            print(f\"Malformed line skipped: {line.strip()}\")\n",
        "            continue\n",
        "\n",
        "        # Extract matched groups\n",
        "        timestamp = match.group(1)\n",
        "        frame_index = int(match.group(2))\n",
        "        x1, y1, x2, y2 = map(int, match.group(3, 4, 5, 6))\n",
        "        object_id = int(match.group(7))\n",
        "        obj_type = match.group(8)\n",
        "        subtype = match.group(9)\n",
        "\n",
        "        data.append({\n",
        "            \"timestamp\": timestamp,\n",
        "            \"frame_index\": frame_index,\n",
        "            \"x1\": x1,\n",
        "            \"y1\": y1,\n",
        "            \"x2\": x2,\n",
        "            \"y2\": y2,\n",
        "            \"object_id\": object_id,\n",
        "            \"type\": obj_type,\n",
        "            \"subtype\": subtype\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Function to load image by frame index\n",
        "def load_image_by_frame(dataset_folder, frame_index):\n",
        "    # Adjust to use 5-digit naming convention\n",
        "    image_path = os.path.join(dataset_folder, f\"frame_{frame_index:06d}.jpg\")\n",
        "    if os.path.exists(image_path):\n",
        "        return cv2.imread(image_path)\n",
        "    else:\n",
        "        print(f\"Image not found: {image_path}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Function to visualize ground truth bounding boxes on an image\n",
        "def visualize_ground_truth(image, bbox, label):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    color = (0, 255, 0)  # Green for bounding box\n",
        "    cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "    cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "    return image\n",
        "\n",
        "\n",
        "def extract_traffic_light_images(dataset_folder, ground_truth):\n",
        "    images = []\n",
        "    labels = []\n",
        "    label_map = {\"go\": 0, \"stop\": 1, \"warning\": 2, \"ambiguous\": 3}  # Map subtypes to numeric labels\n",
        "\n",
        "    for _, row in tqdm(ground_truth.iterrows()):\n",
        "        frame_index = row[\"frame_index\"]\n",
        "        image = load_image_by_frame(dataset_folder, frame_index)\n",
        "        if image is not None:\n",
        "            # Validate and adjust bounding box coordinates\n",
        "            img_height, img_width, _ = image.shape\n",
        "            x1, y1 = max(0, row[\"x1\"]), max(0, row[\"y1\"])\n",
        "            x2, y2 = min(img_width, row[\"x2\"]), min(img_height, row[\"y2\"])\n",
        "\n",
        "            if x1 >= x2 or y1 >= y2:\n",
        "                print(f\"Skipping invalid bounding box: {x1, y1, x2, y2} in frame {frame_index}\")\n",
        "                continue\n",
        "\n",
        "            # Crop and resize the region of interest (ROI)\n",
        "            cropped_img = image[y1:y2, x1:x2]  # Crop the ROI\n",
        "            cropped_img = cv2.resize(cropped_img, (64, 64)) / 255.0  # Resize and normalize\n",
        "            images.append(cropped_img)\n",
        "\n",
        "            # Add the corresponding label\n",
        "            labels.append(label_map[row[\"subtype\"]])  # Use subtype as the label\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "\n",
        "# Main processing logic\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"data preprocessing on LaRA dataset\")\n",
        "    # Path to ground truth file\n",
        "    ground_truth_path = \"/Users/carl/Documents/GitHub/smtThrottle/traffic_light_recognition/dataset/Lara_UrbanSeq1_GroundTruth_GT.txt\"\n",
        "    print(\"reading ground truth txt\")\n",
        "    ground_truth = read_ground_truth(ground_truth_path)\n",
        "    # print(ground_truth.head())\n",
        "\n",
        "    # Path to dataset folder\n",
        "    dataset_folder = \"/Users/carl/Documents/GitHub/smtThrottle/traffic_light_recognition/dataset/Lara3D_UrbanSeq1_JPG/\"\n",
        "\n",
        "    print(\"read dataset images\")\n",
        "    # Extract and prepare dataset\n",
        "    images, labels = extract_traffic_light_images(dataset_folder, ground_truth)\n",
        "    print(f\"Dataset size: {len(images)} images\")\n",
        "\n",
        "    # split into train test split and save dataset\n",
        "    x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    print(f\"Training set size: {len(x_train)} images\")\n",
        "    print(f\"Testing set size: {len(x_test)} images\")\n",
        "\n",
        "    # save dataset\n",
        "    np.save(\"x_train.npy\", x_train)\n",
        "    np.save(\"x_test.npy\", x_test)\n",
        "    np.save(\"y_train.npy\", y_train)\n",
        "    np.save(\"y_test.npy\", y_test)\n",
        "    print(\"dataset saved\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYRzpHg0MMdO",
        "outputId": "8fae521c-03e6-47f2-d839-6e1b0ec078b4"
      },
      "id": "DYRzpHg0MMdO",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ac86dd94-3c97-4b50-b838-b2fe3afbf8b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac86dd94-3c97-4b50-b838-b2fe3afbf8b4",
        "outputId": "769927e4-66f8-4b4f-bcd1-0200caba645b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 111ms/step - accuracy: 0.9191 - loss: 0.2079 - val_accuracy: 0.9902 - val_loss: 0.0315\n",
            "Epoch 2/10\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 104ms/step - accuracy: 0.9905 - loss: 0.0306 - val_accuracy: 0.9924 - val_loss: 0.0291\n",
            "Epoch 3/10\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 109ms/step - accuracy: 0.9898 - loss: 0.0310 - val_accuracy: 0.9853 - val_loss: 0.0376\n",
            "Epoch 4/10\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 121ms/step - accuracy: 0.9927 - loss: 0.0223 - val_accuracy: 0.9869 - val_loss: 0.0374\n",
            "Epoch 5/10\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 110ms/step - accuracy: 0.9941 - loss: 0.0194 - val_accuracy: 0.9973 - val_loss: 0.0127\n",
            "Epoch 6/10\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 107ms/step - accuracy: 0.9978 - loss: 0.0079 - val_accuracy: 0.9956 - val_loss: 0.0147\n",
            "Epoch 7/10\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 102ms/step - accuracy: 0.9948 - loss: 0.0175 - val_accuracy: 0.9978 - val_loss: 0.0109\n",
            "Epoch 8/10\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 101ms/step - accuracy: 0.9981 - loss: 0.0067 - val_accuracy: 0.9973 - val_loss: 0.0104\n",
            "Epoch 9/10\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 103ms/step - accuracy: 0.9978 - loss: 0.0059 - val_accuracy: 0.9945 - val_loss: 0.0182\n",
            "Epoch 10/10\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 143ms/step - accuracy: 0.9984 - loss: 0.0055 - val_accuracy: 0.9951 - val_loss: 0.0193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as output_20250114_003701.h5\n",
            "training done, model saved\n"
          ]
        }
      ],
      "source": [
        "# cnn model to train\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from datetime import datetime\n",
        "\n",
        "# load the god damn model from the npy files because we're now on google colab\n",
        "x_train = np.load(\"/content/drive/My Drive/traffic_light_recognition/x_train.npy\")  # Training images\n",
        "x_test = np.load(\"/content/drive/My Drive/traffic_light_recognition/x_test.npy\")    # Testing images\n",
        "y_train = np.load(\"/content/drive/My Drive/traffic_light_recognition/y_train.npy\")  # Training labels\n",
        "y_test = np.load(\"/content/drive/My Drive/traffic_light_recognition/y_test.npy\")\n",
        "\n",
        "# Build a simple CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(4, activation='softmax')  # 4 classes: \"go\", \"stop\", \"warning\", \"ambiguous\"\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# Format the current timestamp into a safe string\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Save the model with the timestamp in the filename\n",
        "model.save(f\"/content/drive/My Drive/traffic_light_recognition/output/output_{timestamp}.h5\")\n",
        "\n",
        "print(f\"Model saved as output_{timestamp}.h5\")\n",
        "print(\"training done, model saved\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "61813fc2-7b6d-4501-8d35-84d7527ace78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "61813fc2-7b6d-4501-8d35-84d7527ace78",
        "outputId": "2e333f49-747c-4a8c-efbc-00c4fad77d14"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '/content/drive/My Drive/traffic_light_recognition/output/output_20240717_165513.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-287700042ebb>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load the saved model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/My Drive/traffic_light_recognition/output/output_20240717_165513.h5\"\u001b[0m \u001b[0;31m#@param {type:\"string\"}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Load the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    192\u001b[0m         )\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    559\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 561\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/content/drive/My Drive/traffic_light_recognition/output/output_20240717_165513.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the saved model\n",
        "model_path = \"/content/drive/My Drive/traffic_light_recognition/output/output_20240717_165513.h5\" #@param {type:\"string\"}\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Load the test data\n",
        "x_test = np.load(\"/content/drive/My Drive/traffic_light_recognition/x_test.npy\")\n",
        "y_test = np.load(\"/content/drive/My Drive/traffic_light_recognition/y_test.npy\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Generate and print the classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Generate and plot the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}